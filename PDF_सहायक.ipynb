{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnigLe5l0v+lJfoCGXIKJC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Datawithabhishek/PDF-shayak/blob/main/PDF_%E0%A4%B8%E0%A4%B9%E0%A4%BE%E0%A4%AF%E0%A4%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install all Dependencies**"
      ],
      "metadata": {
        "id": "TvXoj0pIPXmK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9aHMh3bPBOD",
        "outputId": "5510d4bf-8a27-4aa1-8add-659f36620a5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.287)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.20)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.36)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.12)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.7.4)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install langchain #build applications using LLMs\n",
        "!pip install openai # access to the OpenAI API\n",
        "!pip install faiss-cpu #efficient similarity search and clustering of dense vectors\n",
        "!pip install PyPDF2 # read and write PDF files\n",
        "!pip install tiktoken #encode text into tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing Libraries**"
      ],
      "metadata": {
        "id": "7HpXVdo0Q3o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS"
      ],
      "metadata": {
        "id": "baQ3fmskPUIg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the key\n",
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = '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'\n"
      ],
      "metadata": {
        "id": "vgMfchInTNGG"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Processing**"
      ],
      "metadata": {
        "id": "lBKMAed2UKne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader('Abhishek_Jain_DS_Resume.pdf')"
      ],
      "metadata": {
        "id": "cSICtWoGUVI2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content"
      ],
      "metadata": {
        "id": "3dgsc927UVPM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "MHhZhSy_UVSN",
        "outputId": "6ba9d7d1-2420-4b59-b45b-fdf75199406a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Abhishek Jain \\nPassionate about learning and growing in the ﬁeld of data science, and actively seeking opportunities to apply analytical abilities to real-world challenges.\\nProﬁcient in Python and SQL, with experience in data analysis and data visualization. Seeking a role in data science to further develop my skills and\\ncontribute to impactful projects. \\ndatawithabhishek@gmail.com \\n8700645673 \\nlinkedin.com/in/Datawithabhishek \\ngithub.com/Datawithabhishek \\nTRAINING EXPERIENCE \\nData Science Trainee \\nAlmabetter\\n \\n \\n11/2022 - Present\\n, \\n \\nBengaluru \\nAcquired proﬁciency in essential data science skills, including \\nFeature Engineering\\n \\n,\\nExploratory Data Analysis (EDA)\\n \\n, and \\nData Visualization\\n \\n. Demonstrated strong\\nteamwork, time management, and problem-solving abilities. Utilized tools such as\\nPower BI\\n \\n, \\nTableau\\n \\nfor hands-on experience. \\nSuccessfully completed impactful projects, including \\nNetﬂix Movies and\\n \\nTV Show\\nClustering\\n, \\nYes Bank Stock Closing Price Prediction\\n and \\nMobile Price Range\\nPrediction.\\n \\nSecured a place in the \\ntop 5% \\nof students in the cohort of \\n400 \\nstudents, which allowed\\nme to work as a \\nSubject Matter Expert \\nfor Doubt Resolution. \\nACADEMIC PROJECTS \\nNetﬂix Movies and TV Shows Clustering \\nAlmabetter Veriﬁed Project\\n \\n \\n03/2023 - 04/2023\\n, \\n \\nDeveloped an \\nUnsupervised ML\\n model for clustering \\nNetﬂix movies and TV shows\\nbased on \\ntext-based\\n attributes. \\nEmployed \\nNLP\\n techniques such as \\nTF-IDF\\n vectorization, \\nstemming\\n, and \\nstopword\\nremoval to preprocess the text data. \\nImplemented \\nK-Means\\n, \\nAgglomerative clustering\\n algorithm to group similar movies\\nand TV shows based on their textual features, using scikit-learn library. \\nEvaluated the optimal number of clusters using the \\nElbow method\\n and \\nDavies-Bouldin\\nscore.\\n \\nMobile Price Range Prediction \\nAlmabetter Veriﬁed Project\\n \\n \\n02/2023 - 03/2023\\n, \\n \\nThe goal\\n \\nis to examine the\\n Correlation\\n between \\nMobile phone attributes\\n (such as RAM\\nand internal memory) and \\nprice range\\n, aiming to gain\\n insights\\n into market dynamics\\nand pricing determinants. \\nIdentiﬁed \\nkey features\\n such as RAM,\\n \\nBattery power, Pixels Dimension and Mobile\\nWeight, which signiﬁcantly inﬂuence mobile phone prices. \\nModel implementation involved ﬁtting various machine learning models, such as\\n KNN\\n,\\nDecision Tree\\n, \\nRandom Forest\\n, \\nLogistic Regression\\n, \\nNaive Bayes\\n, \\nSupport Vector\\nMachine\\n, \\nXgboost\\n and \\nStacking\\n to make predictions on mobile phone prices. \\nDetermined that \\nlogistic regression, \\nStacking \\nmodels performed exceptionally well in\\npredicting mobile phone prices\\n, showcasing their effectiveness in this context. \\nYes Bank Stock Closing Price Prediction \\nAlmabetter Veriﬁed Project\\n \\n \\n01/2023 - 02/2023\\n, \\n \\nThe goal \\nis to \\nbuilt the \\nLinear regression\\n model what can predict the \\nClosing stock\\nprice\\n of the yes bank. \\nPerformed a thorough examination of the data through \\nExploratory analysis\\n, \\nData\\nPreprocessing\\n, \\nHandled outliers\\n, \\nFeature transformation\\n. \\nBuilt \\nlinear regression\\n, \\nRidge regression\\n, \\nLasso \\nregression\\n, \\nElastic Net regression\\n for\\nmodel development. \\nUsed \\nGrid search CV\\n for \\nHyperparameter tuning\\n in all models. The model built by\\nElastic Net Regressor\\n gave the best result with \\nR2 square\\n of\\n 0.9938\\n \\nTECH STACK \\nExpertise in Language & Tools (x/5) \\nPython - 4.5 || SQL - 4.5 || Tableau - 4.5 || Excel - 4.5||\\nPower BI - 4.5 || GitHub - 4.5 || Looker Studio - 4.5 \\nPlatform \\nJupyter notebook, Google Collab, Vs Code, Pycharm,\\nPostgresql \\nML Framework \\nSci-kit Learn, Pandas, NumPy, Matplotlib, Plotly,\\nSeaborn, Flask, NLTK, Streamlit \\nACHIEVEMENTS \\nGold Badge in Python & SQL (01/2023)\\n \\n \\nHacker rank||earned 745 points in python & earned 830\\npoints in SQL \\nLinkedin Badge in Python & SQL (12/2022)\\n \\n \\nAmong Top in 15% in Sql || Among top in 30% in python \\nRELEVANT COURSEWORK \\nPython by Almabetter (11/2022 - 12/2022)\\n \\n \\nSQL by Almabetter\\n (12/2022 - 01/2023)\\n \\n \\nML by Almabetter\\n (01/2023 - 04/2023)\\n \\n \\nPUBLICATIONS \\nMedium Blog \\nMachine Learning in Everyday Life: Unveiling\\nthe Hidden Power\\n \\n \\n2023 \\nMedium Blog \\nMachine Learning Use Case in Aerospace\\n \\n \\n2023 \\nEDUCATION \\nBachelor of Technology \\nDr. A. P. J. Abdul Kalam Technical\\nUniversity, Lucknow\\n \\n \\n07/2018 - 08/2022\\n, \\n \\nC.G.P.A -7.54 \\nAir Canvas Based on Deep Learning(OCV)\\n \\n \\nINTERESTS \\nSketching \\nVideo Games \\nSkills: Supervised ML, Unsupervised ML, Python, SQL, Docker, Streamlit, Flask,Team Work. \\nTags: Unsupervised ML, Clustering, TF-IDF, Elbow method, Davies-Bouldin score \\nTags:Supervised ML, Logistic Regression, KNN, Naive Bayes, Decision Tree, Support Vector Machine \\nTags:Supervised ML, Regression, Lasso Regression, Ridge Regression, Cross-Validation \\nElectronics and Communication Engineering '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "rSCSQWmgU0tV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings**"
      ],
      "metadata": {
        "id": "agJcJf1QU3oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings()\n",
        "document_search = FAISS.from_texts(texts, embeddings)\n",
        "document_search"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QCT0NubIU7El",
        "outputId": "cd6f913d-2f6b-4c89-b6f4-42144ccfb963"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langchain.vectorstores.faiss.FAISS at 0x79db6ee5e770>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model**"
      ],
      "metadata": {
        "id": "5UQpYHCcVOmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "ZSm_SylCVQXt"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "KU8q2KNnVSFg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"what is the name\"\n",
        "docs = document_search.similarity_search(query)\n",
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gQd7iS6YVT0n",
        "outputId": "1a6cf45a-9162-43fe-d9cc-ef364032e5e7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The name is Netﬂix Movies and TV Shows Clustering.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}